{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yIsce4FiKpCO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Input, Dense, Dropout, LeakyReLU\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras import initializers\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10) # reproduction\n",
        "\n",
        "# The dimension of our random noise vector.\n",
        "\n",
        "random_dim = 100\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zeAYlbxILuQA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_minst_data():\n",
        "\n",
        "    # load the data\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # normalize our inputs to be in the range[-1, 1]\n",
        "\n",
        "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "\n",
        "    # convert x_train with a shape of (60000, 28, 28) to (60000, 784)\n",
        "\n",
        "    # so we have 784 columns per row\n",
        "\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "\n",
        "    return (x_train, y_train, x_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oH1Xj1MVLzEJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer():\n",
        "\n",
        "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ehqGluoBMwld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator(optimizer):\n",
        "\n",
        "    generator = Sequential()\n",
        "\n",
        "    generator.add(Dense(256, input_dim=random_dim, \\\n",
        "\n",
        "            kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(512))\n",
        "\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(1024))\n",
        "\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(784, activation='tanh'))\n",
        "\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return generator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UcrKcW5-Nd7K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator(optimizer):\n",
        "\n",
        "    discriminator = Sequential()\n",
        "\n",
        "    discriminator.add(Dense(1024, input_dim=784, \\\n",
        "\n",
        "                kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(512))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(256))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return discriminator\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v--3TX0qP8go"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
        "\n",
        "    # We initially set trainable to False since we only want to train either the\n",
        "\n",
        "    # generator or discriminator at a time\n",
        "\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    # gan input (noise) will be 100-dimensional vectors\n",
        "\n",
        "    gan_input = Input(shape=(random_dim,))\n",
        "\n",
        "    # the output of the generator (an image)\n",
        "\n",
        "    x = generator(gan_input)\n",
        "\n",
        "    # get the output of the discriminator (probability if the image is real or not)\n",
        "\n",
        "    gan_output = discriminator(x)\n",
        "\n",
        "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return gan\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zpYmOmRgP-yR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), \\\n",
        "\n",
        "                          figsize=(10, 10)):\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
        "\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for i in range(generated_images.shape[0]):\n",
        "\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', \\\n",
        "\n",
        "                   cmap='gray_r')\n",
        "\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CjtUOD28QCBO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Check if it's enabled\n",
        "print(\"Eager Execution:\", tf.executing_eagerly())\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(epochs=1, batch_size=128):\n",
        "    # Ensure random_dim is defined before usage\n",
        "    random_dim = 100  # Default value, adjust as needed\n",
        "\n",
        "    # 1. Get the training and testing data\n",
        "    x_train, y_train, x_test, y_test = load_minst_data()\n",
        "\n",
        "    # Split the training data into batches\n",
        "    batch_count = x_train.shape[0] // batch_size\n",
        "\n",
        "    # 2. Build our GAN network\n",
        "    adam = get_optimizer()\n",
        "    generator = get_generator(adam)\n",
        "    discriminator = get_discriminator(adam)\n",
        "    gan = get_gan_network(discriminator, random_dim, generator, adam)  # Now random_dim is defined\n",
        "\n",
        "    for e in range(1, epochs + 1):\n",
        "        print('-' * 15, f'Epoch {e}', '-' * 15)\n",
        "        for _ in tqdm(range(int(batch_count))):\n",
        "            # 4. Get a random set of input noise and images\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "            image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n",
        "\n",
        "            # 5. Generate fake MNIST images\n",
        "            generated_images = generator.predict(noise)\n",
        "            X = np.concatenate([image_batch, generated_images])\n",
        "\n",
        "            # 6. Labels for generated and real data\n",
        "            y_dis = np.zeros(2 * batch_size)\n",
        "\n",
        "            # One-sided label smoothing\n",
        "            y_dis[:batch_size] = 0.9\n",
        "\n",
        "            # 7. Train discriminator\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X, y_dis)\n",
        "\n",
        "            # 8. Train generator\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "            y_gen = np.ones(batch_size)\n",
        "\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "        if e == 1 or e % 20 == 0:\n",
        "            plot_generated_images(e, generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGxoP0WpU8m0",
        "outputId": "584f03dc-a4f4-4acd-94f9-ed0d86456968"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eager Execution: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "8cDzFYPRU9jn",
        "outputId": "59ee5ba2-f54d-4a27-95de-8f22029a7fc8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid non-printable character U+00A0 (<ipython-input-24-e4bcb0417985>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-e4bcb0417985>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    train(20, 128)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A7fxYKYYV5de"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}